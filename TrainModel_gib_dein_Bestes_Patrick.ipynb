{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der benötigten Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_dir = os.getcwd()\n",
    "path_to_soundfilefolder = f'{os_dir}\\\\Datensatz\\\\processed_audio'\n",
    "print(path_to_soundfilefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeug von Librosa\n",
    "#y_harmonic, y_percussive = librosa.effects.hpss(y)  -------> noch beschreiben, was die einzelnen Attribute aussagen\n",
    "#tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "#mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "#mfcc_delta = librosa.feature.delta(mfcc)\n",
    "#beat_mfcc_delta = librosa.util.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "#chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "#beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "#beat_features = np.vstack([beat_chroma, beat_mfcc_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#unsere Attribute\n",
    "attributes = []\n",
    "\n",
    "y, sr = librosa.load(\"C:\\\\Users\\\\Luis\\\\Music_Genre_Git\\\\Datensatz\\\\processed_audio\\\\blues_1_0.wav\")\n",
    "\n",
    "stft_array = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "stft_mean = np.mean(stft_array)\n",
    "stft_var = np.var(stft_array)\n",
    "\n",
    "cq_array = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "cq_mean = np.mean(cq_array)\n",
    "cq_var = np.var(cq_array)\n",
    "\n",
    "rms_array = librosa.feature.rms(y=y)\n",
    "rms_mean = np.mean(rms_array)\n",
    "rms_var = np.var(rms_array)\n",
    "\n",
    "cent_array = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "cent_mean = np.mean(cent_array)\n",
    "cent_var = np.var(cent_array)\n",
    "\n",
    "spec_array = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "spec_mean = np.mean(spec_array)\n",
    "spec_var = np.var(spec_array)\n",
    "\n",
    "rolloff_array = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "rolloff_mean = np.mean(rolloff_array)\n",
    "rolloff_var = np.var(rolloff_array)\n",
    "\n",
    "zero_crossing_rate_array = librosa.feature.zero_crossing_rate(y)\n",
    "zero_crossing_rate_mean = np.mean(zero_crossing_rate_array)\n",
    "zero_crossing_rate_var = np.var(zero_crossing_rate_array)\n",
    "\n",
    "tonnetz_array = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "tonnetz_mean = np.mean(tonnetz_array)\n",
    "tonnetz_var = np.var(tonnetz_array)\n",
    "\n",
    "y_harmonic_array, y_percussive = librosa.effects.hpss(y)\n",
    "tempo1, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "tempo = a = np.float32(tempo1)\n",
    "\n",
    "attributes.extend([stft_mean, stft_var, rms_mean, rms_var, cent_mean, cent_var, spec_mean, spec_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, tonnetz_mean, tonnetz_var]) \n",
    "\n",
    "#für das mfcc-Array und das harmonic-array werden 30 Abschnitte gemacht, für die Attribute bestimmt werden\n",
    "stepwidth = math.floor(len(y_harmonic_array)/30)\n",
    "for i in range(30):\n",
    "    y_harmonic_mean = np.mean(y_harmonic_array[(stepwidth*i):(stepwidth*(i+1))])\n",
    "    y_harmonic_var = np.var(y_harmonic_array[(stepwidth*i):(stepwidth*(i+1))])\n",
    "    print(f\"Harmonic-Zeug: mean {i}: {y_harmonic_mean}, var {i}: {y_harmonic_var}\")\n",
    "    attributes.extend([y_harmonic_mean, y_harmonic_var])\n",
    "        \n",
    "mfcc_array = librosa.feature.mfcc(y=y, sr=sr)\n",
    "for i in range(20):\n",
    "    pass\n",
    "    mfcc_mean = np.mean(mfcc_array[i])\n",
    "    mfcc_var = np.var(mfcc_array[i])\n",
    "    print(f\"mfcc-Zeug: mean {i}: {mfcc_mean}, var {i}: {mfcc_var}\")\n",
    "    attributes.extend([mfcc_mean, mfcc_var])\n",
    "\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der Sound-Dateien\\n\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Zuordnung der Labels zu Zahlen\n",
    "genre_names = []\n",
    "\n",
    "#enthält sämtliche Einträge\n",
    "features = []\n",
    "#enthält die Ergebnisse sämtlicher Einträge\n",
    "genre = []\n",
    "\n",
    "print(path_to_soundfilefolder)\n",
    "\n",
    "for filename in os.listdir(path_to_soundfilefolder):\n",
    "    #hier kommen alle Attribute pro Soundfile rein\n",
    "    attributes = []\n",
    "    \n",
    "    #Umwandlung der Soundfiles in repräsentative Zahlenwerte\n",
    "    print(f\"Converting: {filename}\")\n",
    "    y, sr = librosa.load(f'{os_dir}\\\\Datensatz\\\\processed_audio\\\\' + filename)\n",
    "    \n",
    "    #extrahieren der aussagekräftigen Eigenschaften\n",
    "    stft_array = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    stft_mean = np.mean(stft_array)\n",
    "    stft_var = np.var(stft_array)\n",
    "\n",
    "    cq_array = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    cq_mean = np.mean(cq_array)\n",
    "    cq_var = np.var(cq_array)\n",
    "\n",
    "    rms_array = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms_array)\n",
    "    rms_var = np.var(rms_array)\n",
    "\n",
    "    cent_array = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    cent_mean = np.mean(cent_array)\n",
    "    cent_var = np.var(cent_array)\n",
    "\n",
    "    spec_array = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_mean = np.mean(spec_array)\n",
    "    spec_var = np.var(spec_array)\n",
    "\n",
    "    rolloff_array = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    rolloff_mean = np.mean(rolloff_array)\n",
    "    rolloff_var = np.var(rolloff_array)\n",
    "\n",
    "    zero_crossing_rate_array = librosa.feature.zero_crossing_rate(y)\n",
    "    zero_crossing_rate_mean = np.mean(zero_crossing_rate_array)\n",
    "    zero_crossing_rate_var = np.var(zero_crossing_rate_array)\n",
    "\n",
    "    tonnetz_array = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    tonnetz_mean = np.mean(tonnetz_array)\n",
    "    tonnetz_var = np.var(tonnetz_array)\n",
    "\n",
    "    y_harmonic_array, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo1, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "    tempo = np.float32(tempo1)\n",
    "    \n",
    "    y_harmonic_mean = np.mean(y_harmonic_array)\n",
    "    y_harmonic_var = np.var(y_harmonic_array)\n",
    "\n",
    "    attributes.extend([stft_mean, stft_var, cq_mean, cq_var, rms_mean, rms_var, cent_mean, cent_var, spec_mean, spec_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, tonnetz_mean, tonnetz_var, tempo, y_harmonic_mean, y_harmonic_var]) \n",
    "\n",
    "    #das mfcc-array besteht aus 20 arrays, für die jeweils mean und var bestimmt werden\n",
    "    mfcc_array = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    for i in range(20):\n",
    "        mfcc_mean = np.mean(mfcc_array[i])\n",
    "        mfcc_var = np.var(mfcc_array[i])\n",
    "        attributes.extend([mfcc_mean, mfcc_var])  \n",
    "        \n",
    "    #Erzeugen der Outputs\n",
    "    genre_name = filename.split(\"_\")[0]\n",
    "    if genre_name not in genre_names:\n",
    "        genre_names.append(genre_name)\n",
    "    for i in range(len(genre_names)):\n",
    "        if genre_name == genre_names[i]:\n",
    "            attributes.append(i)\n",
    "            print(genre_name,i)\n",
    "            break\n",
    "            \n",
    "    #Anhängen eines Eintrages\n",
    "    features.append(attributes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array an konvertierten Eigenschaften in CSV speichern\n",
    "features.append(genre)\n",
    "arr = features # Hier muss dann das Ergebnis Array rein\n",
    "headers = [\"stft_mean\", \"stft_var\", \"cq_mean\", \"cq_var\", \"rms_mean\", \"rms_var\", \"cent_mean\", \"cent_var\", \"spec_mean\", \"spec_var\", \"rolloff_mean\", \"rolloff_var\", \"zero_crossing_rate_mean\", \"zero_crossing_rate_var\", \"tonnetz_mean\", \"tonnetz_var\", \"tempo\", \"y_harmonic_mean\", \"y_harmonic_var\", \"mfcc_mean_1\", \"mfcc_var_1\", \"mfcc_mean_2\", \"mfcc_var_2\", \"mfcc_mean_3\", \"mfcc_var_3\", \"mfcc_mean_4\", \"mfcc_var_4\", \"mfcc_mean_5\", \"mfcc_var_5\", \"mfcc_mean_6\", \"mfcc_var_6\", \"mfcc_mean_7\", \"mfcc_var_7\", \"mfcc_mean_8\", \"mfcc_var_8\", \"mfcc_mean_9\", \"mfcc_var_9\", \"mfcc_mean_10\", \"mfcc_var_10\", \"mfcc_mean_11\", \"mfcc_var_11\", \"mfcc_mean_12\", \"mfcc_var_12\", \"mfcc_mean_13\", \"mfcc_var_13\", \"mfcc_mean_14\", \"mfcc_var_14\", \"mfcc_mean_15\", \"mfcc_var_15\", \"mfcc_mean_16\", \"mfcc_var_16\", \"mfcc_mean_17\", \"mfcc_var_17\", \"mfcc_mean_18\", \"mfcc_var_18\", \"mfcc_mean_19\", \"mfcc_var_19\", \"mfcc_mean_20\", \"mfcc_var_20\", \"genre\"] # Das sind die Überschriften\n",
    "df = pd.DataFrame(arr) \n",
    "pd.DataFrame(df).to_csv(f\"{os_dir}\\Datensatz\\\\results.csv\", header = headers, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features[:100])\n",
    "print(genre[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = np.array(genre)\n",
    "feature_list = np.array(features)\n",
    "\n",
    "print(genre_list)\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(feature_list,genre_list,test_size = 0.2,random_state = 42)\n",
    "\n",
    "print(len(x_train))\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Programmierung des Modells\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=300)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestes Modell aus dem Internet\n",
    "model1 = k.models.Sequential([\n",
    "    k.layers.Dense(1024, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    k.layers.Dropout(0.3),\n",
    "    \n",
    "    k.layers.Dense(512, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(256, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(128, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "print(model1.summary())\n",
    "\n",
    "model1.compile(optimizer='rmsprop',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics='accuracy')\n",
    "\n",
    "model1.fit(x_train, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "predictions_confidences = model.predict(x_test)\n",
    "\n",
    "predictions = []\n",
    "for entry in predictions_confidences:\n",
    "        predictions.append(np.argmax(entry))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sklearn.metrics.classification_report(y_test, predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test librosa\n",
    "y, sr = librosa.load(f'{os_dir}\\\\Datensatz\\\\processed_audio\\\\blues_1_0.wav')\n",
    "print(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "print(tempo, beat_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
