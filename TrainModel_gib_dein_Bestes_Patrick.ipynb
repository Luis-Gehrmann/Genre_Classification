{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import der benötigten Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as skp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Notebooks\\Genre_Classification\\Datensatz\\processed_audio\n"
     ]
    }
   ],
   "source": [
    "os_dir = os.getcwd()\n",
    "path_to_soundfilefolder = f'{os_dir}\\\\Datensatz\\\\processed_audio'\n",
    "print(path_to_soundfilefolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeug von Librosa\n",
    "#y_harmonic, y_percussive = librosa.effects.hpss(y)  -------> noch beschreiben, was die einzelnen Attribute aussagen\n",
    "#tempo, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "#mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "#mfcc_delta = librosa.feature.delta(mfcc)\n",
    "#beat_mfcc_delta = librosa.util.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "#chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "#beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "#beat_features = np.vstack([beat_chroma, beat_mfcc_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Notebooks\\Genre_Classification\\Datensatz\\processed_audio\n",
      "Converting: blues_100_0.wav\n",
      "Converting: blues_100_1.wav\n",
      "Converting: blues_100_2.wav\n",
      "Converting: blues_100_3.wav\n",
      "Converting: blues_100_4.wav\n",
      "Converting: blues_100_5.wav\n",
      "Converting: blues_100_6.wav\n",
      "Converting: blues_100_7.wav\n",
      "Converting: blues_100_8.wav\n",
      "Converting: blues_100_9.wav\n",
      "Converting: blues_10_0.wav\n",
      "Converting: blues_10_1.wav\n",
      "Converting: blues_10_2.wav\n",
      "Converting: blues_10_3.wav\n",
      "Converting: blues_10_4.wav\n",
      "Converting: blues_10_5.wav\n",
      "Converting: blues_10_6.wav\n",
      "Converting: blues_10_7.wav\n",
      "Converting: blues_10_8.wav\n",
      "Converting: blues_10_9.wav\n",
      "Converting: blues_11_0.wav\n",
      "Converting: blues_11_1.wav\n",
      "Converting: blues_11_2.wav\n",
      "Converting: blues_11_3.wav\n",
      "Converting: blues_11_4.wav\n",
      "Converting: blues_11_5.wav\n",
      "Converting: blues_11_6.wav\n",
      "Converting: blues_11_7.wav\n",
      "Converting: blues_11_8.wav\n",
      "Converting: blues_11_9.wav\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-7841bb2aefa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mtonnetz_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtonnetz_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0my_harmonic_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_percussive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mtempo1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeat_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeat_track\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_percussive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mtempo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\librosa\\effects.py\u001b[0m in \u001b[0;36mhpss\u001b[1;34m(y, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# Decompose into harmonic and percussives\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mstft_harm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstft_perc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhpss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;31m# Invert the STFTs.  Adjust length to match the input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\librosa\\decompose.py\u001b[0m in \u001b[0;36mhpss\u001b[1;34m(S, kernel_size, power, mask, margin)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;31m# Compute median filters. Pre-allocation here preserves memory layout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mharm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mharm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmedian_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwin_harm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"reflect\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[0mperc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mmedian_filter\u001b[1;34m(input, size, footprint, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \"\"\"\n\u001b[0;32m   1240\u001b[0m     return _rank_filter(input, 0, size, footprint, output, mode, cval,\n\u001b[1;32m-> 1241\u001b[1;33m                         origin, 'median')\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36m_rank_filter\u001b[1;34m(input, rank, size, footprint, output, mode, cval, origin, operation)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m         _nd_image.rank_filter(input, rank, footprint, output, mode, cval,\n\u001b[1;32m-> 1161\u001b[1;33m                               origins)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Import der Sound-Dateien\\n\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Zuordnung der Labels zu Zahlen\n",
    "genre_names = []\n",
    "\n",
    "#enthält sämtliche Einträge\n",
    "features = []\n",
    "#enthält die Ergebnisse sämtlicher Einträge\n",
    "genre = []\n",
    "\n",
    "print(path_to_soundfilefolder)\n",
    "\n",
    "for filename in os.listdir(path_to_soundfilefolder):\n",
    "    #hier kommen alle Attribute pro Soundfile rein\n",
    "    attributes = []\n",
    "    \n",
    "    #Genre einfügen\n",
    "    attributes.append(filename.split(\"_\")[0])\n",
    "    \n",
    "    #Umwandlung der Soundfiles in repräsentative Zahlenwerte\n",
    "    print(f\"Converting: {filename}\")\n",
    "    y, sr = librosa.load(f'{os_dir}\\\\Datensatz\\\\processed_audio\\\\' + filename)\n",
    "    \n",
    "    #extrahieren der aussagekräftigen Eigenschaften\n",
    "    stft_array = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    stft_mean = np.mean(stft_array)\n",
    "    stft_var = np.var(stft_array)\n",
    "\n",
    "    cq_array = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    cq_mean = np.mean(cq_array)\n",
    "    cq_var = np.var(cq_array)\n",
    "\n",
    "    rms_array = librosa.feature.rms(y=y)\n",
    "    rms_mean = np.mean(rms_array)\n",
    "    rms_var = np.var(rms_array)\n",
    "\n",
    "    cent_array = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    cent_mean = np.mean(cent_array)\n",
    "    cent_var = np.var(cent_array)\n",
    "\n",
    "    spec_array = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_mean = np.mean(spec_array)\n",
    "    spec_var = np.var(spec_array)\n",
    "\n",
    "    rolloff_array = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    rolloff_mean = np.mean(rolloff_array)\n",
    "    rolloff_var = np.var(rolloff_array)\n",
    "\n",
    "    zero_crossing_rate_array = librosa.feature.zero_crossing_rate(y)\n",
    "    zero_crossing_rate_mean = np.mean(zero_crossing_rate_array)\n",
    "    zero_crossing_rate_var = np.var(zero_crossing_rate_array)\n",
    "\n",
    "    tonnetz_array = librosa.feature.tonnetz(y=y, sr=sr)\n",
    "    tonnetz_mean = np.mean(tonnetz_array)\n",
    "    tonnetz_var = np.var(tonnetz_array)\n",
    "\n",
    "    y_harmonic_array, y_percussive = librosa.effects.hpss(y)\n",
    "    tempo1, beat_frames = librosa.beat.beat_track(y=y_percussive, sr=sr)\n",
    "    tempo = np.float32(tempo1)\n",
    "    \n",
    "    y_harmonic_mean = np.mean(y_harmonic_array)\n",
    "    y_harmonic_var = np.var(y_harmonic_array)\n",
    "\n",
    "    attributes.extend([stft_mean, stft_var, cq_mean, cq_var, rms_mean, rms_var, cent_mean, cent_var, spec_mean, spec_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, tonnetz_mean, tonnetz_var, tempo, y_harmonic_mean, y_harmonic_var]) \n",
    "\n",
    "    #das mfcc-array besteht aus 20 arrays, für die jeweils mean und var bestimmt werden\n",
    "    mfcc_array = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    for i in range(20):\n",
    "        mfcc_mean = np.mean(mfcc_array[i])\n",
    "        mfcc_var = np.var(mfcc_array[i])\n",
    "        attributes.extend([mfcc_mean, mfcc_var])  \n",
    "        \n",
    "    \n",
    "    \n",
    "    #Anhängen eines Eintrages\n",
    "    features.append(attributes)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array an konvertierten Eigenschaften in CSV speichern\n",
    "arr = features # Hier muss dann das Ergebnis Array rein\n",
    "headers = [\"genre\",\"stft_mean\", \"stft_var\", \"cq_mean\", \"cq_var\", \"rms_mean\", \"rms_var\", \"cent_mean\", \"cent_var\", \"spec_mean\", \"spec_var\", \"rolloff_mean\", \"rolloff_var\", \"zero_crossing_rate_mean\", \"zero_crossing_rate_var\", \"tonnetz_mean\", \"tonnetz_var\", \"tempo\", \"y_harmonic_mean\", \"y_harmonic_var\", \"mfcc_mean_1\", \"mfcc_var_1\", \"mfcc_mean_2\", \"mfcc_var_2\", \"mfcc_mean_3\", \"mfcc_var_3\", \"mfcc_mean_4\", \"mfcc_var_4\", \"mfcc_mean_5\", \"mfcc_var_5\", \"mfcc_mean_6\", \"mfcc_var_6\", \"mfcc_mean_7\", \"mfcc_var_7\", \"mfcc_mean_8\", \"mfcc_var_8\", \"mfcc_mean_9\", \"mfcc_var_9\", \"mfcc_mean_10\", \"mfcc_var_10\", \"mfcc_mean_11\", \"mfcc_var_11\", \"mfcc_mean_12\", \"mfcc_var_12\", \"mfcc_mean_13\", \"mfcc_var_13\", \"mfcc_mean_14\", \"mfcc_var_14\", \"mfcc_mean_15\", \"mfcc_var_15\", \"mfcc_mean_16\", \"mfcc_var_16\", \"mfcc_mean_17\", \"mfcc_var_17\", \"mfcc_mean_18\", \"mfcc_var_18\", \"mfcc_mean_19\", \"mfcc_var_19\", \"mfcc_mean_20\", \"mfcc_var_20\"] # Das sind die Überschriften\n",
    "df = pd.DataFrame(arr) \n",
    "pd.DataFrame(df).to_csv(f\"{os_dir}\\Datensatz\\\\results.csv\", header = headers, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.DataFrame(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5            6   \\\n",
      "0     0.430700  0.079948  0.443360  0.068219  0.056834  0.000283  1189.600872   \n",
      "1     0.401774  0.090328  0.434674  0.064693  0.121461  0.005827  1545.366511   \n",
      "2     0.346437  0.092592  0.447413  0.059083  0.133687  0.003669  1510.988881   \n",
      "3     0.336843  0.078507  0.454218  0.071784  0.089527  0.003820  1576.137830   \n",
      "4     0.360834  0.079291  0.464878  0.071757  0.070490  0.002473  1204.764662   \n",
      "...        ...       ...       ...       ...       ...       ...          ...   \n",
      "9977  0.372667  0.082638  0.262808  0.070318  0.057897  0.000088  1847.993567   \n",
      "9978  0.347207  0.088840  0.284377  0.073732  0.052402  0.000701  1346.166434   \n",
      "9979  0.387354  0.084762  0.248847  0.066627  0.066430  0.000320  2084.876439   \n",
      "9980  0.369244  0.086697  0.291710  0.071916  0.050524  0.000067  1634.338774   \n",
      "9981       NaN       NaN       NaN       NaN       NaN       NaN          NaN   \n",
      "\n",
      "                 7            8              9   ...        49          50  \\\n",
      "0      40380.730173  1722.763902   38270.226455  ... -3.703722   56.100014   \n",
      "1     288470.055570  1778.190868  111097.993441  ...  2.757764   63.667580   \n",
      "2      98819.740394  1440.331627   46955.934603  ... -0.921058  101.638649   \n",
      "3     230355.086009  1829.744846   61057.647435  ... -4.138092   39.541981   \n",
      "4     111759.044762  1733.367179   56417.204741  ... -1.643433   92.797417   \n",
      "...             ...          ...            ...  ...       ...         ...   \n",
      "9977  281007.290736  1906.381942   99815.431686  ...  2.088674   32.480297   \n",
      "9978  662977.657576  1562.051940  139002.057676  ... -1.020712   78.050781   \n",
      "9979  203148.324534  2019.066228   22200.073744  ...  4.123924   28.323929   \n",
      "9980  411437.299384  1867.300771  119680.969895  ...  1.296267   38.766560   \n",
      "9981            NaN          NaN            NaN  ...       NaN         NaN   \n",
      "\n",
      "             51         52        53          54         55          56  \\\n",
      "0     -6.361810  36.836929 -2.265984   43.462280  -8.224248   29.768520   \n",
      "1     -6.137138  43.168053 -5.572185   35.650570  -7.143143   80.402657   \n",
      "2     -7.041173  59.775978 -8.855551  107.414406  -5.609517  166.834045   \n",
      "3     -5.101994  25.728149 -5.089736   35.666714  -3.775420   70.084312   \n",
      "4     -3.886937  33.333706 -5.215451   45.837578  -4.770728   32.664715   \n",
      "...         ...        ...       ...         ...        ...         ...   \n",
      "9977 -12.389524  65.873482 -3.085007   54.283768 -11.963290   63.390671   \n",
      "9978  -2.524271  21.777954  4.799636   25.962273   1.797535   48.307678   \n",
      "9979  -5.370702  17.280420  6.469846   21.370140   2.359090   24.827070   \n",
      "9980 -11.629149  58.856190 -0.163734   55.716457  -6.901930   39.505505   \n",
      "9981        NaN        NaN       NaN         NaN        NaN         NaN   \n",
      "\n",
      "             57          58  \n",
      "0    -13.833816   47.202095  \n",
      "1     -5.006261  121.538483  \n",
      "2      5.338740   92.822701  \n",
      "3     -4.379102   25.362917  \n",
      "4     -5.662903   15.365190  \n",
      "...         ...         ...  \n",
      "9977   0.404298   18.759733  \n",
      "9978  -0.320112   41.750008  \n",
      "9979   0.688447   12.747363  \n",
      "9980  -3.406076   31.736723  \n",
      "9981        NaN         NaN  \n",
      "\n",
      "[9982 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'Datensatz//results.csv')\n",
    "\n",
    "data = df.iloc[0:, 1:]\n",
    "song_labels = data['genre']\n",
    "label_index = dict()\n",
    "\n",
    "for i, x in enumerate(df.label.unique()):\n",
    "    label_index[x] = i\n",
    "\n",
    "labels = []\n",
    "\n",
    "#print(len(song_labels))\n",
    "for x in range(len(song_labels)):\n",
    "    labels.append(label_index[song_labels[x]])\n",
    "\n",
    "genre_list = pd.DataFrame(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "cols = features.columns\n",
    "min_max_scaler = skp.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(features)\n",
    "features_normalized = pd.DataFrame(np_scaled, columns = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
      "0        0.0         -0.954024         0.755136 -0.846810 -0.553232   \n",
      "1        0.0         -1.461998         0.699073 -0.384951  0.258831   \n",
      "2        0.0          0.843479         1.517352  2.043859  2.069544   \n",
      "3        0.0         -2.127091         0.570655 -1.241262 -0.694352   \n",
      "4        0.0         -0.767909         1.456974 -0.461418  0.811581   \n",
      "...      ...               ...              ...       ...       ...   \n",
      "7987     0.0         -1.240592         1.141071 -0.477121  0.323693   \n",
      "7988     0.0         -1.457300        -0.327524 -1.305664 -0.712068   \n",
      "7989     0.0         -1.548909         0.915723 -0.683575 -0.104507   \n",
      "7990     0.0         -0.153339         0.762706 -0.325390 -0.105628   \n",
      "7991     0.0          0.503368        -0.456082  0.631459 -0.204434   \n",
      "\n",
      "      spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
      "0                   0.756545              -0.385804                 0.610042   \n",
      "1                  -0.746612              -0.556426                -0.867779   \n",
      "2                   1.277027               1.809685                 1.962884   \n",
      "3                  -0.885463              -0.735831                -0.060960   \n",
      "4                   0.225053               2.336651                 0.635193   \n",
      "...                      ...                    ...                      ...   \n",
      "7987                0.248373               0.168030                 0.591789   \n",
      "7988               -1.071237              -0.833411                -0.702996   \n",
      "7989               -1.323242              -0.709074                -1.574424   \n",
      "7990               -0.913173               1.957540                -0.848400   \n",
      "7991                0.743767               0.115340                 1.143863   \n",
      "\n",
      "      spectral_bandwidth_var  rolloff_mean  ...  mfcc16_mean  mfcc16_var  \\\n",
      "0                   0.193040      0.607928  ...     0.370722   -0.699393   \n",
      "1                  -0.555343     -0.852432  ...    -0.892663    1.339395   \n",
      "2                   0.563936      1.647886  ...    -0.356427   -0.460323   \n",
      "3                  -0.648683     -0.910056  ...     1.522035    1.313962   \n",
      "4                   3.371110      0.261426  ...    -1.035090    0.641811   \n",
      "...                      ...           ...  ...          ...         ...   \n",
      "7987                2.410392      0.400583  ...    -1.274146   -0.521616   \n",
      "7988               -0.778005     -0.957520  ...     0.991537   -0.124559   \n",
      "7989               -0.934948     -1.286835  ...    -0.767744    0.803345   \n",
      "7990                1.584471     -1.014840  ...     1.050513    0.669255   \n",
      "7991               -0.015334      0.821490  ...    -1.342870   -0.379324   \n",
      "\n",
      "      mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n",
      "0        1.420491   -0.733139    -0.564192   -0.744044     0.446219   \n",
      "1       -0.623044    1.512190     0.326697    1.803546     0.736195   \n",
      "2        0.695382    0.169674    -0.271454   -0.160694    -0.180563   \n",
      "3        0.401615    0.408774    -2.145423    0.730065     1.173097   \n",
      "4       -0.155828   -0.428603     0.889530   -0.117288     0.521065   \n",
      "...           ...         ...          ...         ...          ...   \n",
      "7987    -0.069357   -0.444527    -0.976942   -0.704484    -0.128205   \n",
      "7988     0.043326   -1.042104     0.173073   -0.952148     0.767288   \n",
      "7989     1.199583   -0.259580     0.108838    0.074789     0.799385   \n",
      "7990    -0.714254    2.246508    -0.089452   -0.275618    -0.413710   \n",
      "7991     0.264084    0.322994     0.460846    0.363268     1.426585   \n",
      "\n",
      "      mfcc19_var  mfcc20_mean  mfcc20_var  \n",
      "0       0.544036     2.816301    1.231225  \n",
      "1       1.414848     0.677303    1.959393  \n",
      "2      -0.698277    -0.546562   -0.260602  \n",
      "3       1.224220     0.374148    2.483154  \n",
      "4      -0.373676    -1.488230    0.440897  \n",
      "...          ...          ...         ...  \n",
      "7987   -0.568717    -1.078543    0.131531  \n",
      "7988   -0.575297     3.076734    1.686395  \n",
      "7989   -0.147535     0.559551    0.834705  \n",
      "7990    0.266003    -0.162361   -0.640920  \n",
      "7991   -0.046167     0.421895    0.516941  \n",
      "\n",
      "[7992 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(features_normalized,genre_list,test_size = 0.2,random_state = 42)\n",
    "\n",
    "scaler = skp.StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "250/250 [==============================] - 1s 755us/step - loss: 1.9283 - accuracy: 0.3010\n",
      "Epoch 2/300\n",
      "250/250 [==============================] - 0s 706us/step - loss: 1.0853 - accuracy: 0.6232\n",
      "Epoch 3/300\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.8417 - accuracy: 0.7129\n",
      "Epoch 4/300\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.7477 - accuracy: 0.7498\n",
      "Epoch 5/300\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.6382 - accuracy: 0.7791\n",
      "Epoch 6/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.5880 - accuracy: 0.8010\n",
      "Epoch 7/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.5552 - accuracy: 0.8139\n",
      "Epoch 8/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.5051 - accuracy: 0.8302\n",
      "Epoch 9/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.4570 - accuracy: 0.8461\n",
      "Epoch 10/300\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4162 - accuracy: 0.8645\n",
      "Epoch 11/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.4052 - accuracy: 0.8644\n",
      "Epoch 12/300\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.3859 - accuracy: 0.8691\n",
      "Epoch 13/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3519 - accuracy: 0.8822\n",
      "Epoch 14/300\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3294 - accuracy: 0.8891\n",
      "Epoch 15/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.3023 - accuracy: 0.8960\n",
      "Epoch 16/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.2927 - accuracy: 0.8971\n",
      "Epoch 17/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.2674 - accuracy: 0.9094\n",
      "Epoch 18/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.2559 - accuracy: 0.9174\n",
      "Epoch 19/300\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.2422 - accuracy: 0.9186\n",
      "Epoch 20/300\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.2332 - accuracy: 0.9225\n",
      "Epoch 21/300\n",
      "250/250 [==============================] - 0s 947us/step - loss: 0.2156 - accuracy: 0.9315\n",
      "Epoch 22/300\n",
      "250/250 [==============================] - 0s 743us/step - loss: 0.2073 - accuracy: 0.9308\n",
      "Epoch 23/300\n",
      "250/250 [==============================] - 0s 747us/step - loss: 0.1769 - accuracy: 0.9422\n",
      "Epoch 24/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.1713 - accuracy: 0.9465\n",
      "Epoch 25/300\n",
      "250/250 [==============================] - 0s 741us/step - loss: 0.1630 - accuracy: 0.9477\n",
      "Epoch 26/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.1541 - accuracy: 0.9540\n",
      "Epoch 27/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.1535 - accuracy: 0.9525\n",
      "Epoch 28/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.1422 - accuracy: 0.9558\n",
      "Epoch 29/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.1298 - accuracy: 0.9631\n",
      "Epoch 30/300\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.1374 - accuracy: 0.9550\n",
      "Epoch 31/300\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.1104 - accuracy: 0.9673\n",
      "Epoch 32/300\n",
      "250/250 [==============================] - 0s 939us/step - loss: 0.1075 - accuracy: 0.9658\n",
      "Epoch 33/300\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.1232 - accuracy: 0.9603\n",
      "Epoch 34/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0949 - accuracy: 0.9747\n",
      "Epoch 35/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.0944 - accuracy: 0.9726\n",
      "Epoch 36/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0862 - accuracy: 0.9755\n",
      "Epoch 37/300\n",
      "250/250 [==============================] - 0s 733us/step - loss: 0.0834 - accuracy: 0.9774\n",
      "Epoch 38/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0874 - accuracy: 0.9756\n",
      "Epoch 39/300\n",
      "250/250 [==============================] - 0s 759us/step - loss: 0.0717 - accuracy: 0.9815\n",
      "Epoch 40/300\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.0862 - accuracy: 0.9748\n",
      "Epoch 41/300\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.0747 - accuracy: 0.9810\n",
      "Epoch 42/300\n",
      "250/250 [==============================] - 0s 791us/step - loss: 0.0687 - accuracy: 0.9792\n",
      "Epoch 43/300\n",
      "250/250 [==============================] - 0s 930us/step - loss: 0.0585 - accuracy: 0.9864\n",
      "Epoch 44/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0614 - accuracy: 0.9804\n",
      "Epoch 45/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.0603 - accuracy: 0.9841\n",
      "Epoch 46/300\n",
      "250/250 [==============================] - 0s 747us/step - loss: 0.0545 - accuracy: 0.9837\n",
      "Epoch 47/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0579 - accuracy: 0.9811\n",
      "Epoch 48/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.0498 - accuracy: 0.9879\n",
      "Epoch 49/300\n",
      "250/250 [==============================] - 0s 958us/step - loss: 0.0493 - accuracy: 0.9857\n",
      "Epoch 50/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.0452 - accuracy: 0.9889\n",
      "Epoch 51/300\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.0437 - accuracy: 0.9891\n",
      "Epoch 52/300\n",
      "250/250 [==============================] - 0s 767us/step - loss: 0.0491 - accuracy: 0.9853\n",
      "Epoch 53/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0537 - accuracy: 0.9834\n",
      "Epoch 54/300\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.0413 - accuracy: 0.9882\n",
      "Epoch 55/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0353 - accuracy: 0.9929\n",
      "Epoch 56/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0463 - accuracy: 0.9873\n",
      "Epoch 57/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0488 - accuracy: 0.9864\n",
      "Epoch 58/300\n",
      "250/250 [==============================] - 0s 979us/step - loss: 0.0366 - accuracy: 0.9898\n",
      "Epoch 59/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0394 - accuracy: 0.9885\n",
      "Epoch 60/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0387 - accuracy: 0.9877\n",
      "Epoch 61/300\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.0383 - accuracy: 0.9901\n",
      "Epoch 62/300\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.0457 - accuracy: 0.98520s - loss: 0.0476 - accuracy: \n",
      "Epoch 63/300\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.0315 - accuracy: 0.9910\n",
      "Epoch 64/300\n",
      "250/250 [==============================] - 0s 747us/step - loss: 0.0179 - accuracy: 0.9981\n",
      "Epoch 65/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0249 - accuracy: 0.9939\n",
      "Epoch 66/300\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.0270 - accuracy: 0.9946\n",
      "Epoch 67/300\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.0485 - accuracy: 0.9825\n",
      "Epoch 68/300\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.0364 - accuracy: 0.9883\n",
      "Epoch 69/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0589 - accuracy: 0.9825\n",
      "Epoch 70/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0195 - accuracy: 0.9959\n",
      "Epoch 71/300\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.0204 - accuracy: 0.9959\n",
      "Epoch 72/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0139 - accuracy: 0.9984\n",
      "Epoch 73/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0122 - accuracy: 0.9973\n",
      "Epoch 74/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0102 - accuracy: 0.9987\n",
      "Epoch 75/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0202 - accuracy: 0.9958\n",
      "Epoch 76/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.1095 - accuracy: 0.9669\n",
      "Epoch 77/300\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.0656 - accuracy: 0.9767\n",
      "Epoch 78/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0302 - accuracy: 0.9904\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 678us/step - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 80/300\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0121 - accuracy: 0.9977\n",
      "Epoch 81/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0135 - accuracy: 0.9970\n",
      "Epoch 82/300\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.0121 - accuracy: 0.9982\n",
      "Epoch 83/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0104 - accuracy: 0.9982\n",
      "Epoch 84/300\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.0217 - accuracy: 0.9942\n",
      "Epoch 85/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0352 - accuracy: 0.9880\n",
      "Epoch 86/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0661 - accuracy: 0.9760\n",
      "Epoch 87/300\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.0381 - accuracy: 0.9870\n",
      "Epoch 88/300\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.0428 - accuracy: 0.9847\n",
      "Epoch 89/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0278 - accuracy: 0.9910\n",
      "Epoch 90/300\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.0293 - accuracy: 0.9904\n",
      "Epoch 91/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0126 - accuracy: 0.9977\n",
      "Epoch 92/300\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.0109 - accuracy: 0.9982\n",
      "Epoch 93/300\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 94/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0095 - accuracy: 0.9981\n",
      "Epoch 95/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0166 - accuracy: 0.9954\n",
      "Epoch 96/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0679 - accuracy: 0.9772\n",
      "Epoch 97/300\n",
      "250/250 [==============================] - 0s 751us/step - loss: 0.0354 - accuracy: 0.9875\n",
      "Epoch 98/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0091 - accuracy: 0.9988\n",
      "Epoch 99/300\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.0098 - accuracy: 0.9979\n",
      "Epoch 100/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0115 - accuracy: 0.9970\n",
      "Epoch 101/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0088 - accuracy: 0.9988\n",
      "Epoch 102/300\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.0101 - accuracy: 0.9981\n",
      "Epoch 103/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0074 - accuracy: 0.9984\n",
      "Epoch 104/300\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.0094 - accuracy: 0.9984\n",
      "Epoch 105/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.1207 - accuracy: 0.9648\n",
      "Epoch 106/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0624 - accuracy: 0.9774\n",
      "Epoch 107/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0174 - accuracy: 0.9943\n",
      "Epoch 108/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0086 - accuracy: 0.9983\n",
      "Epoch 109/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0074 - accuracy: 0.9983\n",
      "Epoch 110/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0084 - accuracy: 0.9983\n",
      "Epoch 111/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 112/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0074 - accuracy: 0.9981\n",
      "Epoch 113/300\n",
      "250/250 [==============================] - 0s 767us/step - loss: 0.0055 - accuracy: 0.9988\n",
      "Epoch 114/300\n",
      "250/250 [==============================] - 0s 887us/step - loss: 0.0203 - accuracy: 0.9940\n",
      "Epoch 115/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.1227 - accuracy: 0.9651\n",
      "Epoch 116/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0348 - accuracy: 0.9892\n",
      "Epoch 117/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0160 - accuracy: 0.9952\n",
      "Epoch 118/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0112 - accuracy: 0.9972\n",
      "Epoch 119/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 120/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0061 - accuracy: 0.9987\n",
      "Epoch 121/300\n",
      "250/250 [==============================] - 0s 697us/step - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 122/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0033 - accuracy: 0.9995\n",
      "Epoch 123/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 124/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0550 - accuracy: 0.9821\n",
      "Epoch 125/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0789 - accuracy: 0.9757\n",
      "Epoch 126/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0269 - accuracy: 0.9911\n",
      "Epoch 127/300\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.0087 - accuracy: 0.9990\n",
      "Epoch 128/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 129/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0044 - accuracy: 0.9992\n",
      "Epoch 130/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 131/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 132/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 133/300\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.0415 - accuracy: 0.9842\n",
      "Epoch 134/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0245 - accuracy: 0.9908\n",
      "Epoch 135/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0182 - accuracy: 0.9923\n",
      "Epoch 136/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0139 - accuracy: 0.9977\n",
      "Epoch 137/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 138/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0095 - accuracy: 0.9983\n",
      "Epoch 139/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0063 - accuracy: 0.9989\n",
      "Epoch 140/300\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.0449 - accuracy: 0.9852\n",
      "Epoch 141/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0759 - accuracy: 0.9773\n",
      "Epoch 142/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0235 - accuracy: 0.9934\n",
      "Epoch 143/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0088 - accuracy: 0.9974\n",
      "Epoch 144/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 145/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0066 - accuracy: 0.9984\n",
      "Epoch 146/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0047 - accuracy: 0.9990\n",
      "Epoch 147/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0090 - accuracy: 0.9983\n",
      "Epoch 148/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 149/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 150/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0977 - accuracy: 0.9705\n",
      "Epoch 151/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0348 - accuracy: 0.9883\n",
      "Epoch 152/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0139 - accuracy: 0.9962\n",
      "Epoch 153/300\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.0097 - accuracy: 0.9979\n",
      "Epoch 154/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0060 - accuracy: 0.9989\n",
      "Epoch 155/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 156/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 662us/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 158/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 159/300\n",
      "250/250 [==============================] - 0s 657us/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 160/300\n",
      "250/250 [==============================] - 0s 646us/step - loss: 0.0629 - accuracy: 0.9816\n",
      "Epoch 161/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0727 - accuracy: 0.9749\n",
      "Epoch 162/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 163/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0083 - accuracy: 0.9978\n",
      "Epoch 164/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 165/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 166/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 167/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0108 - accuracy: 0.9962\n",
      "Epoch 168/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 169/300\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0068 - accuracy: 0.9986\n",
      "Epoch 170/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0677 - accuracy: 0.9811\n",
      "Epoch 171/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0584 - accuracy: 0.9811\n",
      "Epoch 172/300\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.0136 - accuracy: 0.9954\n",
      "Epoch 173/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 174/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0060 - accuracy: 0.9990\n",
      "Epoch 175/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0043 - accuracy: 0.9991\n",
      "Epoch 176/300\n",
      "250/250 [==============================] - 0s 646us/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 177/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 178/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 179/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0289 - accuracy: 0.9908\n",
      "Epoch 180/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0836 - accuracy: 0.9733\n",
      "Epoch 181/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 182/300\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0103 - accuracy: 0.9971\n",
      "Epoch 183/300\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.99 - 0s 674us/step - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 184/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0074 - accuracy: 0.9982\n",
      "Epoch 185/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 186/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 187/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 188/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 189/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0439 - accuracy: 0.9886\n",
      "Epoch 190/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0678 - accuracy: 0.9786\n",
      "Epoch 191/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0219 - accuracy: 0.9937\n",
      "Epoch 192/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0082 - accuracy: 0.9983\n",
      "Epoch 193/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 194/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0027 - accuracy: 0.9998\n",
      "Epoch 195/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0036 - accuracy: 0.9994\n",
      "Epoch 196/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0022 - accuracy: 0.9997\n",
      "Epoch 197/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0089 - accuracy: 0.9974\n",
      "Epoch 198/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0222 - accuracy: 0.9925\n",
      "Epoch 199/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.1084 - accuracy: 0.9703\n",
      "Epoch 200/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0246 - accuracy: 0.9903\n",
      "Epoch 201/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0079 - accuracy: 0.9976\n",
      "Epoch 202/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 203/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 204/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 205/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0101 - accuracy: 0.9976\n",
      "Epoch 206/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 207/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 208/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.1131 - accuracy: 0.9702\n",
      "Epoch 209/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0414 - accuracy: 0.9875\n",
      "Epoch 210/300\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 211/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0157 - accuracy: 0.9950\n",
      "Epoch 212/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0045 - accuracy: 0.9989\n",
      "Epoch 213/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 214/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 215/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0070 - accuracy: 0.9984\n",
      "Epoch 216/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 217/300\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 218/300\n",
      "250/250 [==============================] - 0s 767us/step - loss: 0.0108 - accuracy: 0.9971\n",
      "Epoch 219/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0775 - accuracy: 0.9756\n",
      "Epoch 220/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0336 - accuracy: 0.9904\n",
      "Epoch 221/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0144 - accuracy: 0.9947\n",
      "Epoch 222/300\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.0072 - accuracy: 0.9984\n",
      "Epoch 223/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0044 - accuracy: 0.9991\n",
      "Epoch 224/300\n",
      "250/250 [==============================] - 0s 963us/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 225/300\n",
      "250/250 [==============================] - 0s 855us/step - loss: 0.0100 - accuracy: 0.9974\n",
      "Epoch 226/300\n",
      "250/250 [==============================] - 0s 807us/step - loss: 0.0063 - accuracy: 0.9985\n",
      "Epoch 227/300\n",
      "250/250 [==============================] - 0s 891us/step - loss: 0.0161 - accuracy: 0.9948\n",
      "Epoch 228/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0343 - accuracy: 0.9883\n",
      "Epoch 229/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0795 - accuracy: 0.9756\n",
      "Epoch 230/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0097 - accuracy: 0.9978\n",
      "Epoch 231/300\n",
      "250/250 [==============================] - 0s 995us/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 232/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0031 - accuracy: 0.9995\n",
      "Epoch 233/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 662us/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 235/300\n",
      "250/250 [==============================] - 0s 649us/step - loss: 0.0054 - accuracy: 0.9991\n",
      "Epoch 236/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 237/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 238/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0121 - accuracy: 0.9960\n",
      "Epoch 239/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.1092 - accuracy: 0.9667\n",
      "Epoch 240/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0421 - accuracy: 0.9874\n",
      "Epoch 241/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 242/300\n",
      "250/250 [==============================] - 0s 927us/step - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 243/300\n",
      "250/250 [==============================] - 0s 684us/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 244/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0064 - accuracy: 0.9988\n",
      "Epoch 245/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 246/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 247/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 248/300\n",
      "250/250 [==============================] - 0s 653us/step - loss: 0.0076 - accuracy: 0.9979\n",
      "Epoch 249/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0234 - accuracy: 0.9931\n",
      "Epoch 250/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0670 - accuracy: 0.9770\n",
      "Epoch 251/300\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.99 - 0s 670us/step - loss: 0.0219 - accuracy: 0.9931\n",
      "Epoch 252/300\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 253/300\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 254/300\n",
      "250/250 [==============================] - 0s 657us/step - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 255/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 256/300\n",
      "250/250 [==============================] - 0s 959us/step - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 257/300\n",
      "250/250 [==============================] - 0s 811us/step - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 258/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0044 - accuracy: 0.9991\n",
      "Epoch 259/300\n",
      "250/250 [==============================] - 0s 654us/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 260/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 261/300\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 262/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.1592 - accuracy: 0.9596\n",
      "Epoch 263/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0261 - accuracy: 0.9909\n",
      "Epoch 264/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0163 - accuracy: 0.9955\n",
      "Epoch 265/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 266/300\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 267/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 268/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 269/300\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 270/300\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 271/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 272/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 273/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0310 - accuracy: 0.9906\n",
      "Epoch 274/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0569 - accuracy: 0.9836\n",
      "Epoch 275/300\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 276/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 277/300\n",
      "250/250 [==============================] - 0s 658us/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 278/300\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 279/300\n",
      "250/250 [==============================] - 0s 650us/step - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 280/300\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 281/300\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 282/300\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 283/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 284/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0649 - accuracy: 0.9800\n",
      "Epoch 285/300\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.0413 - accuracy: 0.9867\n",
      "Epoch 286/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0278 - accuracy: 0.9918\n",
      "Epoch 287/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 288/300\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.0035 - accuracy: 0.9984\n",
      "Epoch 289/300\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 290/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0025 - accuracy: 0.9996\n",
      "Epoch 291/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 292/300\n",
      "250/250 [==============================] - 0s 686us/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 293/300\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.0037 - accuracy: 0.9992\n",
      "Epoch 294/300\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.0226 - accuracy: 0.9936\n",
      "Epoch 295/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0756 - accuracy: 0.9787\n",
      "Epoch 296/300\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 297/300\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 298/300\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 299/300\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 300/300\n",
      "250/250 [==============================] - 0s 690us/step - loss: 0.0051 - accuracy: 0.9984\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                3776      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 6,554\n",
      "Trainable params: 6,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Programmierung des Modells\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=300)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestes Modell aus dem Internet\n",
    "model1 = k.models.Sequential([\n",
    "    k.layers.Dense(1024, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    k.layers.Dropout(0.3),\n",
    "    \n",
    "    k.layers.Dense(512, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(256, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(128, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dropout(0.3),\n",
    "\n",
    "    k.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "print(model1.summary())\n",
    "\n",
    "model1.compile(optimizer='rmsprop',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics='accuracy')\n",
    "\n",
    "model1.fit(x_train, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "predictions_confidences = model.predict(x_test)\n",
    "\n",
    "predictions = []\n",
    "for entry in predictions_confidences:\n",
    "        predictions.append(np.argmax(entry))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sklearn.metrics.classification_report(y_test, predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test librosa\n",
    "y, sr = librosa.load(f'{os_dir}\\\\Datensatz\\\\processed_audio\\\\blues_1_0.wav')\n",
    "print(y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "print(tempo, beat_frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
